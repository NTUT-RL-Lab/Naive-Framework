n_timestep = 500000          # total training timesteps needed
c_lr = 0.01                  # learning rate
cap = 250                    # cap for environment switching
c_transition_loss = 0.5      # transition loss coefficient
policy = "MlpPolicy"         # policy identifier
eval_freq = 10               # evaluation frequency
eval_episodes = 5            # number of evaluation episodes
seed = 42                    # random seed
device = "cuda"              # computation device
env_weights = [1]
env_ids = ["LunarLander-v2"]
